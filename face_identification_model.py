# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10vGusIe4XxxVeDNmHnRzOjcHTn0JEtNk
"""

from google.colab import drive
drive.mount('/content/drive')


!unzip -oq "/content/drive/MyDrive/faceRecognitionp_project/Comys_Hackathon5.zip" -d /content/

!cp -r "/content/drive/MyDrive/faceRecognitionp_project/Comys_Hackathon5/Task_B" /content/

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import models, transforms
from PIL import Image
from tqdm import tqdm
from torch.utils.data import DataLoader,Dataset
from torch.utils.data import ConcatDataset


#train and val paths
train_dir = "/content/Comys_Hackathon5/Task_B/train"
val_dir = "/content/Comys_Hackathon5/Task_B/val"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

#transforms
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
    transforms.RandomHorizontalFlip()
])

all_paths = set(os.listdir(train_dir)) | set(os.listdir(val_dir))
all_paths = sorted(list(all_paths))     # consistent ordering
label_to_index = {label: idx for idx, label in enumerate(all_paths)}
index_to_label = {idx: label for label, idx in label_to_index.items()}

class Face_detect(Dataset):
    def __init__(self, root_dir, label_to_index, transform=None):
        self.images_path = []
        self.labels = []
        self.transform = transform
        for fold in os.listdir(root_dir):
            fold_paths = os.path.join(root_dir, fold)
            #distortion file
            dist_path = os.path.join(fold_paths, "distortion")
            if os.path.exists(dist_path):
                for i in os.listdir(dist_path):
                    self.images_path.append(os.path.join(dist_path, i))
                    self.labels.append(label_to_index[fold])
            #original file
            for files in os.listdir(fold_paths):
                if files != "distortion" and os.path.isfile(os.path.join(fold_paths, files)):
                    self.images_path.append(os.path.join(fold_paths, files))
                    self.labels.append(label_to_index[fold])

    def __len__(self):
        return len(self.images_path)

    def __getitem__(self, idx):
        image_path = self.images_path[idx]
        label = self.labels[idx]
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, label

#datset
train_dataset = Face_detect(root_dir=train_dir,label_to_index=label_to_index, transform=transform)
val_dataset = Face_detect(root_dir=val_dir,label_to_index=label_to_index, transform=transform)

all_dataset=ConcatDataset([train_dataset,val_dataset])
#dataloader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
all_loader=DataLoader(all_dataset,batch_size=32,shuffle=True)
#  Load and Modify ResNet18 ---
model = models.resnet18(pretrained=True)
for name, param in model.named_parameters():
    if "layer4" not in name and "layer3" not in name:
        param.requires_grad = False


n_classes = len(label_to_index)
model.fc = nn.Sequential(
    nn.Linear(512, 512),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(512, n_classes)
)
model = model.to(device)

#  Define Loss and Optimizer ---
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=1e-4,
    weight_decay=1e-4
)
# Training Loop ---
epochs = 20
for e in range(epochs):
    print(f"\nüîÅ Epoch {e+1}/{epochs}")
    model.train()
    for image, label in tqdm(all_loader, desc="Training"): # Use train_loader
        image, label = image.to(device), label.to(device)

        outputs = model(image)
        loss = criterion(outputs, label)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()



# Validation Loop ---
model.eval()
total, correct = 0, 0
with torch.no_grad():
    for image, label in val_loader:
        image, label = image.to(device), label.to(device)
        outputs = model(image)
        _, predicted = torch.max(outputs.data, 1)
        total += label.size(0)
        correct += (predicted == label).sum().item()

val_acc = 100 * correct / total
print(f"\n‚úÖ Validation Accuracy: {val_acc:.2f}%")

# --- STEP 10: Save Model ---
torch.save(model.state_dict(), "face_identification_model.pth")
print("‚úÖ Model saved as face_identification_model.pth")

from google.colab import files
files.download("face_identification_model.pth")
print("Model saved successfully!")